{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd7aaada",
   "metadata": {},
   "source": [
    "# Module 8: Packaging and Containerization with Docker\n",
    "\n",
    "**Course**: End-to-End Machine Learning (Datacamp)  \n",
    "**Case Study**: CardioCare Heart Disease Prediction  \n",
    "**Author**: Seif\n",
    "\n",
    "---\n",
    "\n",
    "## Why containerize?\n",
    "\n",
    "Containers package your app + its dependencies into a portable, reproducible unit that runs the same across environments.\n",
    "- Reproducibility and isolation\n",
    "- Fast deploys and consistent runtime\n",
    "- Easy to integrate with CI/CD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904c29b6",
   "metadata": {},
   "source": [
    "## What we'll build\n",
    "\n",
    "We'll create a tiny Flask service `app.py` with a `/predict` endpoint that accepts a JSON payload with a few heart-disease-style features (cp, thalach, ca, thal) and returns a dummy risk prediction. Then we'll containerize it with a Dockerfile, and show how to build/run the image locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4db3fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a minimal Flask service to app.py\n",
    "app_code = '''\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.get('/health')\n",
    "def health():\n",
    "    return {'status': 'ok'}\n",
    "\n",
    "def simple_rule_predict(payload):\n",
    "    # Very simple rule-based demo: NOT A REAL MODEL!\n",
    "    # risk = 1 if (thalach < 150) or (ca >= 2) or (cp >= 2), else 0\n",
    "    cp = int(payload.get('cp', 0))\n",
    "    thalach = int(payload.get('thalach', 190))\n",
    "    ca = int(payload.get('ca', 0))\n",
    "    thal = int(payload.get('thal', 0))  # unused in this rule, but included\n",
    "    risk = 1 if (thalach < 150) or (ca >= 2) or (cp >= 2) else 0\n",
    "    return risk\n",
    "\n",
    "@app.post('/predict')\n",
    "def predict():\n",
    "    try:\n",
    "        payload = request.get_json(force=True, silent=False) or {}\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': f'Invalid JSON: {str(e)}'}), 400\n",
    "\n",
    "    missing = [k for k in ['cp','thalach','ca','thal'] if k not in payload]\n",
    "    if missing:\n",
    "        return jsonify({'error': f'Missing keys: {missing}'}), 400\n",
    "\n",
    "    pred = simple_rule_predict(payload)\n",
    "    return jsonify({'prediction': int(pred)})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Default Flask dev server (for demo purposes). In production, use gunicorn/uvicorn.\n",
    "    app.run(host='0.0.0.0', port=8000, debug=False)\n",
    "'''\n",
    "\n",
    "with open('app.py', 'w', encoding='utf-8') as f:\n",
    "    f.write(app_code)\n",
    "print('Wrote app.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550b2af5",
   "metadata": {},
   "source": [
    "## Dockerfile\n",
    "\n",
    "We'll use the official Python slim image, copy our code, install Flask, and expose port 8000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabdf1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a Dockerfile to the project root\n",
    "dockerfile = '''\n",
    "# syntax=docker/dockerfile:1.7-labs\n",
    "FROM python:3.11-slim AS base\n",
    "\n",
    "# Security/size best practices: no cache, no extra packages\n",
    "ENV PYTHONDONTWRITEBYTECODE=1 \\\n",
    "    PYTHONUNBUFFERED=1\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "# Optionally copy a requirements file and install\n",
    "# If you have a project requirements.txt, uncomment the next two lines and remove the RUN pip install flask below\n",
    "# COPY requirements.txt .\n",
    "# RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# For this demo, we only need Flask\n",
    "RUN pip install --no-cache-dir flask\n",
    "\n",
    "# Copy the app code\n",
    "COPY app.py ./\n",
    "\n",
    "# Health and runtime config\n",
    "EXPOSE 8000\n",
    "ENV APP_ENV=production\n",
    "\n",
    "# Run the service\n",
    "CMD [\"python\", \"app.py\"]\n",
    "'''\n",
    "\n",
    "with open('Dockerfile', 'w', encoding='utf-8') as f:\n",
    "    f.write(dockerfile)\n",
    "print('Wrote Dockerfile')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40aec97f",
   "metadata": {},
   "source": [
    "## Build and run (PowerShell)\n",
    "\n",
    "```powershell\n",
    "# Build the image from the Dockerfile in the project root\n",
    "docker build -t heart_disease_model:latest .\n",
    "\n",
    "# Run the container, mapping port 8000\n",
    "docker run --rm -p 8000:8000 -e APP_ENV=production heart_disease_model:latest\n",
    "```\n",
    "\n",
    "In another terminal, test the endpoint:\n",
    "\n",
    "```powershell\n",
    "$body = @{ cp = 2; thalach = 140; ca = 1; thal = 2 } | ConvertTo-Json\n",
    "Invoke-RestMethod -Uri http://localhost:8000/predict -Method Post -ContentType 'application/json' -Body $body | ConvertTo-Json\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1218a153",
   "metadata": {},
   "source": [
    "## Tagging images\n",
    "\n",
    "```powershell\n",
    "docker tag heart_disease_model:latest heart_disease_model:v1\n",
    "```\n",
    "\n",
    "Push to a registry (example):\n",
    "\n",
    "```powershell\n",
    "docker tag heart_disease_model:latest <your-registry>/heart_disease_model:latest\n",
    "docker push <your-registry>/heart_disease_model:latest\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5e7c3a",
   "metadata": {},
   "source": [
    "## Best practices & security\n",
    "\n",
    "- Use trusted base images and pin versions\n",
    "- Keep images small (slim base, no-cache, remove build deps)\n",
    "- Don't bake secrets into images; pass via env vars or secret managers\n",
    "- Consider a non-root user in containers for production\n",
    "- Use multi-stage builds for compiled deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc73b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a .dockerignore to keep images smaller and safer\n",
    "contents = \"\"\"\n",
    "# Bytecode and caches\n",
    "__pycache__/\n",
    "*.pyc\n",
    "*.pyo\n",
    "\n",
    "# Venvs\n",
    ".venv/\n",
    "venv/\n",
    "\n",
    "# VCS\n",
    ".git/\n",
    ".gitignore\n",
    "\n",
    "# Jupyter\n",
    ".ipynb_checkpoints/\n",
    "notebooks/\n",
    "\n",
    "# Local data and artifacts\n",
    "mlruns/\n",
    "data/\n",
    "*.parquet\n",
    "*.csv\n",
    "\n",
    "# OS/editor files\n",
    ".DS_Store\n",
    "Thumbs.db\n",
    ".vscode/\n",
    "\n",
    "# Tests (optional exclude)\n",
    "tests/\n",
    "\"\"\"\n",
    "with open('.dockerignore', 'w', encoding='utf-8') as f:\n",
    "    f.write(contents)\n",
    "print('Wrote .dockerignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4bab9d",
   "metadata": {},
   "source": [
    "## Load a real model: MLflow or local joblib\n",
    "\n",
    "We'll create a production-ready variant `app_model.py` that tries to:\n",
    "- Load a model from MLflow using `MLFLOW_MODEL_URI` (e.g., `models:/CardioCareHeartDiseaseLR/Production`)\n",
    "- Otherwise load a local `model.joblib`\n",
    "- Otherwise fall back to the simple rule from earlier\n",
    "\n",
    "It accepts JSON with keys `cp`, `thalach`, `ca`, `thal` and returns predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff18f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write app_model.py that loads a model from MLflow or joblib\n",
    "app_code = '''\n",
    "from flask import Flask, request, jsonify\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "MLFLOW_MODEL_URI = os.getenv(\"MLFLOW_MODEL_URI\")\n",
    "MODEL_PATH = os.getenv(\"MODEL_PATH\", \"model.joblib\")\n",
    "\n",
    "_mlflow_model = None\n",
    "_sklearn_model = None\n",
    "\n",
    "# Try MLflow first\n",
    "if MLFLOW_MODEL_URI:\n",
    "    try:\n",
    "        import mlflow.pyfunc\n",
    "        _mlflow_model = mlflow.pyfunc.load_model(MLFLOW_MODEL_URI)\n",
    "        print(f\"Loaded MLflow model from {MLFLOW_MODEL_URI}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load MLflow model: {e}\")\n",
    "\n",
    "# Try local joblib if MLflow not available\n",
    "if _mlflow_model is None and os.path.exists(MODEL_PATH):\n",
    "    try:\n",
    "        import joblib\n",
    "        _sklearn_model = joblib.load(MODEL_PATH)\n",
    "        print(f\"Loaded local model from {MODEL_PATH}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load local joblib model: {e}\")\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.get('/health')\n",
    "def health():\n",
    "    return {'status': 'ok'}\n",
    "\n",
    "FEATURES = [\"cp\", \"thalach\", \"ca\", \"thal\"]\n",
    "\n",
    "def _predict_payloads(records):\n",
    "    if _mlflow_model is not None:\n",
    "        # MLflow models generally accept DataFrame inputs\n",
    "        df = pd.DataFrame(records)\n",
    "        preds = _mlflow_model.predict(df)\n",
    "        # Ensure JSON-serializable\n",
    "        try:\n",
    "            arr = np.array(preds).astype(int).tolist()\n",
    "        except Exception:\n",
    "            arr = np.array(preds).tolist()\n",
    "        return arr\n",
    "    elif _sklearn_model is not None:\n",
    "        X = []\n",
    "        for r in records:\n",
    "            X.append([\n",
    "                int(r.get('cp', 0)),\n",
    "                int(r.get('thalach', 190)),\n",
    "                int(r.get('ca', 0)),\n",
    "                int(r.get('thal', 0)),\n",
    "            ])\n",
    "        X = np.array(X)\n",
    "        preds = _sklearn_model.predict(X)\n",
    "        return np.array(preds).astype(int).tolist()\n",
    "    else:\n",
    "        # Fallback to simple rule\n",
    "        out = []\n",
    "        for r in records:\n",
    "            cp = int(r.get('cp', 0))\n",
    "            thalach = int(r.get('thalach', 190))\n",
    "            ca = int(r.get('ca', 0))\n",
    "            # thal unused in this toy rule\n",
    "            risk = 1 if (thalach < 150) or (ca >= 2) or (cp >= 2) else 0\n",
    "            out.append(risk)\n",
    "        return out\n",
    "\n",
    "@app.post('/predict')\n",
    "def predict():\n",
    "    try:\n",
    "        payload = request.get_json(force=True, silent=False)\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': f'Invalid JSON: {e}'}), 400\n",
    "\n",
    "    if payload is None:\n",
    "        return jsonify({'error': 'Empty payload'}), 400\n",
    "\n",
    "    # Accept a single object or a list of objects\n",
    "    if isinstance(payload, dict):\n",
    "        records = [payload]\n",
    "    elif isinstance(payload, list):\n",
    "        records = payload\n",
    "    else:\n",
    "        return jsonify({'error': 'Payload must be an object or array of objects'}), 400\n",
    "\n",
    "    # Basic key check\n",
    "    missing = [k for k in FEATURES if k not in records[0]]\n",
    "    if missing:\n",
    "        return jsonify({'error': f'Missing keys (example record): {missing}'}), 400\n",
    "\n",
    "    preds = _predict_payloads(records)\n",
    "    # Return single or list depending on input\n",
    "    if isinstance(payload, dict):\n",
    "        return jsonify({'prediction': int(preds[0])})\n",
    "    return jsonify({'predictions': preds})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=8000, debug=False)\n",
    "'''\n",
    "\n",
    "with open('app_model.py', 'w', encoding='utf-8') as f:\n",
    "    f.write(app_code)\n",
    "print('Wrote app_model.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e71adb",
   "metadata": {},
   "source": [
    "## Dockerfile for model-serving (requirements + MLflow/joblib)\n",
    "\n",
    "We'll write `Dockerfile.model` which:\n",
    "- Installs your repo `requirements.txt` (includes scikit-learn and mlflow)\n",
    "- Copies `app_model.py`\n",
    "- Optionally copies a `model.joblib` if you add it to the project root\n",
    "\n",
    "Build and run examples are provided after this cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c969ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Dockerfile.model that serves app_model.py\n",
    "content = '''\n",
    "# syntax=docker/dockerfile:1.7-labs\n",
    "FROM python:3.11-slim\n",
    "\n",
    "ENV PYTHONDONTWRITEBYTECODE=1 \\\n",
    "    PYTHONUNBUFFERED=1\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "# Install requirements (includes mlflow, scikit-learn, etc.)\n",
    "COPY requirements.txt ./\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# Copy the serving app and (optionally) a local model artifact\n",
    "COPY app_model.py ./\n",
    "# If you have a model file in the project root, uncomment next line\n",
    "# COPY model.joblib ./model.joblib\n",
    "\n",
    "EXPOSE 8000\n",
    "\n",
    "# Config via env vars (set at runtime)\n",
    "# ENV MLFLOW_TRACKING_URI=\"http://127.0.0.1:5000\"\n",
    "# ENV MLFLOW_MODEL_URI=\"models:/CardioCareHeartDiseaseLR/Production\"\n",
    "\n",
    "CMD [\"python\", \"app_model.py\"]\n",
    "'''\n",
    "with open('Dockerfile.model', 'w', encoding='utf-8') as f:\n",
    "    f.write(content)\n",
    "print('Wrote Dockerfile.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f081c97",
   "metadata": {},
   "source": [
    "## Build and run the model-serving image (PowerShell)\n",
    "\n",
    "```powershell\n",
    "# Build from Dockerfile.model\n",
    "docker build -f Dockerfile.model -t heart_disease_model:mlflow .\n",
    "\n",
    "# Option A: Run with MLflow model registry (requires running tracking server or Databricks, etc.)\n",
    "# Replace the MLFLOW_MODEL_URI with your own (e.g., a registered model + stage)\n",
    "docker run --rm -p 8000:8000 `\n",
    "  -e MLFLOW_TRACKING_URI=\"http://127.0.0.1:5000\" `\n",
    "  -e MLFLOW_MODEL_URI=\"models:/CardioCareHeartDiseaseLR/Production\" `\n",
    "  heart_disease_model:mlflow\n",
    "\n",
    "# Option B: Run with a local joblib model (place model.joblib in project root and uncomment COPY in Dockerfile.model)\n",
    "# docker run --rm -p 8000:8000 heart_disease_model:mlflow\n",
    "\n",
    "# Test the endpoint (single record)\n",
    "$body = @{ cp = 2; thalach = 140; ca = 1; thal = 2 } | ConvertTo-Json\n",
    "Invoke-RestMethod -Uri http://localhost:8000/predict -Method Post -ContentType 'application/json' -Body $body | ConvertTo-Json\n",
    "\n",
    "# Test the endpoint (batch)\n",
    "$batch = @(\n",
    "  @{ cp = 0; thalach = 170; ca = 0; thal = 2 },\n",
    "  @{ cp = 3; thalach = 130; ca = 2; thal = 3 }\n",
    ") | ConvertTo-Json\n",
    "Invoke-RestMethod -Uri http://localhost:8000/predict -Method Post -ContentType 'application/json' -Body $batch | ConvertTo-Json\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
